{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit1d867bd8aa154576b0fa62babcf552d0",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "086317466957d500e1e3add5d1080e4cde135e955220d9fc98fd7fe59df8a909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from x_transformers import Encoder as PT_Encoder\n",
    "from tf_x_transformers import Encoder as TF_Encoder\n",
    "pt_x = torch.randn(12,128,768)\n",
    "tf_x = tf.constant(pt_x.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\yujun\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "ndepths = 6\n",
    "rel_pos_bias = True\n",
    "rotary_pos_emb = True\n",
    "gate_residual = True\n",
    "pre_norm = False\n",
    "macaron = False\n",
    "use_scalenorm = use_rmsnorm = use_rezero = False\n",
    "pt_model = PT_Encoder(\n",
    "    dim=768,\n",
    "    depth=ndepths,\n",
    "    heads=12,\n",
    "    rel_pos_bias=rel_pos_bias,\n",
    "    rotary_pos_emb=rotary_pos_emb,\n",
    "    attn_dim_head=64,\n",
    "    gate_residual=gate_residual,\n",
    "    pre_norm=pre_norm,\n",
    ")\n",
    "pt_model.eval()\n",
    "class TMP(keras.Model):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = TF_Encoder(\n",
    "            dim=768,\n",
    "            depth=ndepths,\n",
    "            heads=12,\n",
    "            rel_pos_bias=rel_pos_bias,\n",
    "            rotary_pos_emb=rotary_pos_emb,\n",
    "            attn_dim_head=64,\n",
    "            gate_residual=gate_residual,\n",
    "            pre_norm=pre_norm\n",
    "        )\n",
    "    def call(self,x):\n",
    "        return self.model(x)\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "tf_model = TMP()\n",
    "dummp = tf_model(tf_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skipping non-model layer _CHECKPOINTABLE_OBJECT_GRAPH\n"
     ]
    }
   ],
   "source": [
    "tf_path = \"./ckpts/checkpoint\"\n",
    "tf_model.save_weights(tf_path)  \n",
    "init_vars = tf.train.list_variables(tf_path)\n",
    "names = []\n",
    "arrays = []\n",
    "layer_depth = []\n",
    "for full_name, shape in init_vars:\n",
    "    if full_name == \"_CHECKPOINTABLE_OBJECT_GRAPH\" or full_name[0] in [\"global_step\", \"save_counter\"]:\n",
    "        print(f\"Skipping non-model layer {full_name}\")\n",
    "        continue\n",
    "    names.append(full_name.replace(\".ATTRIBUTES/VARIABLE_VALUE\",\"\"))\n",
    "    array = tf.train.load_variable(tf_path, full_name)\n",
    "    array = torch.from_numpy(array)\n",
    "    if \"kernel\" in names[-1]:\n",
    "        array = array.T\n",
    "    arrays.append(array)\n",
    "mmap = dict(zip(names,arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/rel_pos/relative_attention_bias/embeddings/',\n",
       " 'model/tf_layers/0/0/beta/',\n",
       " 'model/tf_layers/0/0/gamma/',\n",
       " 'model/tf_layers/0/1/to_k/kernel/',\n",
       " 'model/tf_layers/0/1/to_out/bias/',\n",
       " 'model/tf_layers/0/1/to_out/kernel/',\n",
       " 'model/tf_layers/0/1/to_q/kernel/',\n",
       " 'model/tf_layers/0/1/to_v/kernel/',\n",
       " 'model/tf_layers/0/2/gru/bias/',\n",
       " 'model/tf_layers/0/2/gru/kernel/',\n",
       " 'model/tf_layers/0/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/1/0/beta/',\n",
       " 'model/tf_layers/1/0/gamma/',\n",
       " 'model/tf_layers/1/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/1/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/1/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/1/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/1/2/gru/bias/',\n",
       " 'model/tf_layers/1/2/gru/kernel/',\n",
       " 'model/tf_layers/1/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/10/0/beta/',\n",
       " 'model/tf_layers/10/0/gamma/',\n",
       " 'model/tf_layers/10/1/to_k/kernel/',\n",
       " 'model/tf_layers/10/1/to_out/bias/',\n",
       " 'model/tf_layers/10/1/to_out/kernel/',\n",
       " 'model/tf_layers/10/1/to_q/kernel/',\n",
       " 'model/tf_layers/10/1/to_v/kernel/',\n",
       " 'model/tf_layers/10/2/gru/bias/',\n",
       " 'model/tf_layers/10/2/gru/kernel/',\n",
       " 'model/tf_layers/10/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/11/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/11/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/11/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/11/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/11/2/gru/bias/',\n",
       " 'model/tf_layers/11/2/gru/kernel/',\n",
       " 'model/tf_layers/11/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/2/0/beta/',\n",
       " 'model/tf_layers/2/0/gamma/',\n",
       " 'model/tf_layers/2/1/to_k/kernel/',\n",
       " 'model/tf_layers/2/1/to_out/bias/',\n",
       " 'model/tf_layers/2/1/to_out/kernel/',\n",
       " 'model/tf_layers/2/1/to_q/kernel/',\n",
       " 'model/tf_layers/2/1/to_v/kernel/',\n",
       " 'model/tf_layers/2/2/gru/bias/',\n",
       " 'model/tf_layers/2/2/gru/kernel/',\n",
       " 'model/tf_layers/2/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/3/0/beta/',\n",
       " 'model/tf_layers/3/0/gamma/',\n",
       " 'model/tf_layers/3/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/3/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/3/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/3/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/3/2/gru/bias/',\n",
       " 'model/tf_layers/3/2/gru/kernel/',\n",
       " 'model/tf_layers/3/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/4/0/beta/',\n",
       " 'model/tf_layers/4/0/gamma/',\n",
       " 'model/tf_layers/4/1/to_k/kernel/',\n",
       " 'model/tf_layers/4/1/to_out/bias/',\n",
       " 'model/tf_layers/4/1/to_out/kernel/',\n",
       " 'model/tf_layers/4/1/to_q/kernel/',\n",
       " 'model/tf_layers/4/1/to_v/kernel/',\n",
       " 'model/tf_layers/4/2/gru/bias/',\n",
       " 'model/tf_layers/4/2/gru/kernel/',\n",
       " 'model/tf_layers/4/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/5/0/beta/',\n",
       " 'model/tf_layers/5/0/gamma/',\n",
       " 'model/tf_layers/5/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/5/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/5/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/5/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/5/2/gru/bias/',\n",
       " 'model/tf_layers/5/2/gru/kernel/',\n",
       " 'model/tf_layers/5/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/6/0/beta/',\n",
       " 'model/tf_layers/6/0/gamma/',\n",
       " 'model/tf_layers/6/1/to_k/kernel/',\n",
       " 'model/tf_layers/6/1/to_out/bias/',\n",
       " 'model/tf_layers/6/1/to_out/kernel/',\n",
       " 'model/tf_layers/6/1/to_q/kernel/',\n",
       " 'model/tf_layers/6/1/to_v/kernel/',\n",
       " 'model/tf_layers/6/2/gru/bias/',\n",
       " 'model/tf_layers/6/2/gru/kernel/',\n",
       " 'model/tf_layers/6/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/7/0/beta/',\n",
       " 'model/tf_layers/7/0/gamma/',\n",
       " 'model/tf_layers/7/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/7/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/7/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/7/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/7/2/gru/bias/',\n",
       " 'model/tf_layers/7/2/gru/kernel/',\n",
       " 'model/tf_layers/7/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/8/0/beta/',\n",
       " 'model/tf_layers/8/0/gamma/',\n",
       " 'model/tf_layers/8/1/to_k/kernel/',\n",
       " 'model/tf_layers/8/1/to_out/bias/',\n",
       " 'model/tf_layers/8/1/to_out/kernel/',\n",
       " 'model/tf_layers/8/1/to_q/kernel/',\n",
       " 'model/tf_layers/8/1/to_v/kernel/',\n",
       " 'model/tf_layers/8/2/gru/bias/',\n",
       " 'model/tf_layers/8/2/gru/kernel/',\n",
       " 'model/tf_layers/8/2/gru/recurrent_kernel/',\n",
       " 'model/tf_layers/9/0/beta/',\n",
       " 'model/tf_layers/9/0/gamma/',\n",
       " 'model/tf_layers/9/1/net/layer_with_weights-0/bias/',\n",
       " 'model/tf_layers/9/1/net/layer_with_weights-0/kernel/',\n",
       " 'model/tf_layers/9/1/net/layer_with_weights-1/bias/',\n",
       " 'model/tf_layers/9/1/net/layer_with_weights-1/kernel/',\n",
       " 'model/tf_layers/9/2/gru/bias/',\n",
       " 'model/tf_layers/9/2/gru/kernel/',\n",
       " 'model/tf_layers/9/2/gru/recurrent_kernel/']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layers.0.0.weight torch.Size([768])\nlayers.0.0.bias torch.Size([768])\nlayers.0.1.to_q.weight torch.Size([768, 768])\nlayers.0.1.to_k.weight torch.Size([768, 768])\nlayers.0.1.to_v.weight torch.Size([768, 768])\nlayers.0.1.to_out.weight torch.Size([768, 768])\nlayers.0.1.to_out.bias torch.Size([768])\nlayers.0.2.gru.weight_ih torch.Size([2304, 768])\nlayers.0.2.gru.weight_hh torch.Size([2304, 768])\nlayers.0.2.gru.bias_ih torch.Size([2304])\nlayers.0.2.gru.bias_hh torch.Size([2304])\nlayers.1.0.weight torch.Size([768])\nlayers.1.0.bias torch.Size([768])\nlayers.1.1.net.0.0.weight torch.Size([3072, 768])\nlayers.1.1.net.0.0.bias torch.Size([3072])\nlayers.1.1.net.2.weight torch.Size([768, 3072])\nlayers.1.1.net.2.bias torch.Size([768])\nlayers.1.2.gru.weight_ih torch.Size([2304, 768])\nlayers.1.2.gru.weight_hh torch.Size([2304, 768])\nlayers.1.2.gru.bias_ih torch.Size([2304])\nlayers.1.2.gru.bias_hh torch.Size([2304])\nlayers.2.0.weight torch.Size([768])\nlayers.2.0.bias torch.Size([768])\nlayers.2.1.to_q.weight torch.Size([768, 768])\nlayers.2.1.to_k.weight torch.Size([768, 768])\nlayers.2.1.to_v.weight torch.Size([768, 768])\nlayers.2.1.to_out.weight torch.Size([768, 768])\nlayers.2.1.to_out.bias torch.Size([768])\nlayers.2.2.gru.weight_ih torch.Size([2304, 768])\nlayers.2.2.gru.weight_hh torch.Size([2304, 768])\nlayers.2.2.gru.bias_ih torch.Size([2304])\nlayers.2.2.gru.bias_hh torch.Size([2304])\nlayers.3.0.weight torch.Size([768])\nlayers.3.0.bias torch.Size([768])\nlayers.3.1.net.0.0.weight torch.Size([3072, 768])\nlayers.3.1.net.0.0.bias torch.Size([3072])\nlayers.3.1.net.2.weight torch.Size([768, 3072])\nlayers.3.1.net.2.bias torch.Size([768])\nlayers.3.2.gru.weight_ih torch.Size([2304, 768])\nlayers.3.2.gru.weight_hh torch.Size([2304, 768])\nlayers.3.2.gru.bias_ih torch.Size([2304])\nlayers.3.2.gru.bias_hh torch.Size([2304])\nlayers.4.0.weight torch.Size([768])\nlayers.4.0.bias torch.Size([768])\nlayers.4.1.to_q.weight torch.Size([768, 768])\nlayers.4.1.to_k.weight torch.Size([768, 768])\nlayers.4.1.to_v.weight torch.Size([768, 768])\nlayers.4.1.to_out.weight torch.Size([768, 768])\nlayers.4.1.to_out.bias torch.Size([768])\nlayers.4.2.gru.weight_ih torch.Size([2304, 768])\nlayers.4.2.gru.weight_hh torch.Size([2304, 768])\nlayers.4.2.gru.bias_ih torch.Size([2304])\nlayers.4.2.gru.bias_hh torch.Size([2304])\nlayers.5.0.weight torch.Size([768])\nlayers.5.0.bias torch.Size([768])\nlayers.5.1.net.0.0.weight torch.Size([3072, 768])\nlayers.5.1.net.0.0.bias torch.Size([3072])\nlayers.5.1.net.2.weight torch.Size([768, 3072])\nlayers.5.1.net.2.bias torch.Size([768])\nlayers.5.2.gru.weight_ih torch.Size([2304, 768])\nlayers.5.2.gru.weight_hh torch.Size([2304, 768])\nlayers.5.2.gru.bias_ih torch.Size([2304])\nlayers.5.2.gru.bias_hh torch.Size([2304])\nlayers.6.0.weight torch.Size([768])\nlayers.6.0.bias torch.Size([768])\nlayers.6.1.to_q.weight torch.Size([768, 768])\nlayers.6.1.to_k.weight torch.Size([768, 768])\nlayers.6.1.to_v.weight torch.Size([768, 768])\nlayers.6.1.to_out.weight torch.Size([768, 768])\nlayers.6.1.to_out.bias torch.Size([768])\nlayers.6.2.gru.weight_ih torch.Size([2304, 768])\nlayers.6.2.gru.weight_hh torch.Size([2304, 768])\nlayers.6.2.gru.bias_ih torch.Size([2304])\nlayers.6.2.gru.bias_hh torch.Size([2304])\nlayers.7.0.weight torch.Size([768])\nlayers.7.0.bias torch.Size([768])\nlayers.7.1.net.0.0.weight torch.Size([3072, 768])\nlayers.7.1.net.0.0.bias torch.Size([3072])\nlayers.7.1.net.2.weight torch.Size([768, 3072])\nlayers.7.1.net.2.bias torch.Size([768])\nlayers.7.2.gru.weight_ih torch.Size([2304, 768])\nlayers.7.2.gru.weight_hh torch.Size([2304, 768])\nlayers.7.2.gru.bias_ih torch.Size([2304])\nlayers.7.2.gru.bias_hh torch.Size([2304])\nlayers.8.0.weight torch.Size([768])\nlayers.8.0.bias torch.Size([768])\nlayers.8.1.to_q.weight torch.Size([768, 768])\nlayers.8.1.to_k.weight torch.Size([768, 768])\nlayers.8.1.to_v.weight torch.Size([768, 768])\nlayers.8.1.to_out.weight torch.Size([768, 768])\nlayers.8.1.to_out.bias torch.Size([768])\nlayers.8.2.gru.weight_ih torch.Size([2304, 768])\nlayers.8.2.gru.weight_hh torch.Size([2304, 768])\nlayers.8.2.gru.bias_ih torch.Size([2304])\nlayers.8.2.gru.bias_hh torch.Size([2304])\nlayers.9.0.weight torch.Size([768])\nlayers.9.0.bias torch.Size([768])\nlayers.9.1.net.0.0.weight torch.Size([3072, 768])\nlayers.9.1.net.0.0.bias torch.Size([3072])\nlayers.9.1.net.2.weight torch.Size([768, 3072])\nlayers.9.1.net.2.bias torch.Size([768])\nlayers.9.2.gru.weight_ih torch.Size([2304, 768])\nlayers.9.2.gru.weight_hh torch.Size([2304, 768])\nlayers.9.2.gru.bias_ih torch.Size([2304])\nlayers.9.2.gru.bias_hh torch.Size([2304])\nlayers.10.0.weight torch.Size([768])\nlayers.10.0.bias torch.Size([768])\nlayers.10.1.to_q.weight torch.Size([768, 768])\nlayers.10.1.to_k.weight torch.Size([768, 768])\nlayers.10.1.to_v.weight torch.Size([768, 768])\nlayers.10.1.to_out.weight torch.Size([768, 768])\nlayers.10.1.to_out.bias torch.Size([768])\nlayers.10.2.gru.weight_ih torch.Size([2304, 768])\nlayers.10.2.gru.weight_hh torch.Size([2304, 768])\nlayers.10.2.gru.bias_ih torch.Size([2304])\nlayers.10.2.gru.bias_hh torch.Size([2304])\nlayers.11.0.weight torch.Size([768])\nlayers.11.0.bias torch.Size([768])\nlayers.11.1.net.0.0.weight torch.Size([3072, 768])\nlayers.11.1.net.0.0.bias torch.Size([3072])\nlayers.11.1.net.2.weight torch.Size([768, 3072])\nlayers.11.1.net.2.bias torch.Size([768])\nlayers.11.2.gru.weight_ih torch.Size([2304, 768])\nlayers.11.2.gru.weight_hh torch.Size([2304, 768])\nlayers.11.2.gru.bias_ih torch.Size([2304])\nlayers.11.2.gru.bias_hh torch.Size([2304])\nrotary_pos_emb.inv_freq torch.Size([16])\nrel_pos.relative_attention_bias.weight torch.Size([32, 12])\n"
     ]
    }
   ],
   "source": [
    "for k,v in pt_model.state_dict().items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(x):\n",
    "    z,r,h= x.chunk(3,dim=0)\n",
    "    return torch.cat([r,z,h],dim=0)\n",
    "\n",
    "# rel_pos_bias\n",
    "if rel_pos_bias and 'model/rel_pos/relative_attention_bias/embeddings/' in mmap:\n",
    "    pt_model.rel_pos.relative_attention_bias.weight.data = mmap['model/rel_pos/relative_attention_bias/embeddings/']\n",
    "\n",
    "for i,layer in enumerate(pt_model.layer_types):\n",
    "    is_last = i==len(pt_model.layer_types)-1\n",
    "    i = str(i)\n",
    "\n",
    "    if layer == \"f\" :\n",
    "        if macaron:\n",
    "            getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").fn.net,\"0\"),\"0\").weight.data = mmap[f\"model/tf_layers/{i}/1/fn/net/layer_with_weights-0/kernel/\"]\n",
    "            getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").fn.net,\"0\"),\"0\").bias.data = mmap[f\"model/tf_layers/{i}/1/fn/net/layer_with_weights-0/bias/\"]\n",
    "            getattr(getattr(getattr(pt_model.layers,i),\"1\").fn.net,\"2\").weight.data = mmap[f\"model/tf_layers/{i}/1/fn/net/layer_with_weights-1/kernel/\"]\n",
    "            getattr(getattr(getattr(pt_model.layers,i),\"1\").fn.net,\"2\").bias.data = mmap[f\"model/tf_layers/{i}/1/fn/net/layer_with_weights-1/bias/\"]\n",
    "        else:\n",
    "            if not is_last:\n",
    "                if use_scalenorm or use_rmsnorm:\n",
    "                    getattr(getattr(pt_model.layers,i),\"0\").g.data = mmap[f\"model/tf_layers/{i}/0/g/\"]\n",
    "\n",
    "                else:\n",
    "                    getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"model/tf_layers/{i}/0/gamma/\"]\n",
    "                    getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"model/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "            getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").weight.data = mmap[f\"model/tf_layers/{i}/1/net/layer_with_weights-0/kernel/\"]\n",
    "            getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").bias.data = mmap[f\"model/tf_layers/{i}/1/net/layer_with_weights-0/bias/\"]\n",
    "            getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").weight.data = mmap[f\"model/tf_layers/{i}/1/net/layer_with_weights-1/kernel/\"]\n",
    "            getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").bias.data = mmap[f\"model/tf_layers/{i}/1/net/layer_with_weights-1/bias/\"]\n",
    "\n",
    "    elif layer ==\"a\" or layer==\"c\":\n",
    "        if use_scalenorm or use_rmsnorm or use_rezero:\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").g.data = mmap[f\"model/tf_layers/{i}/0/g/\"]\n",
    "        else:\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"model/tf_layers/{i}/0/gamma/\"]\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"model/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "        try:\n",
    "            getattr(getattr(pt_model.layers,i),\"1\").post_softmax_proj.data = mmap[f\"model/tf_layers/{i}/1/post_softmax_proj/\"]\n",
    "            getattr(getattr(pt_model.layers,i),\"1\").pre_softmax_proj.data = mmap[f\"model/tf_layers/{i}/1/pre_softmax_proj/\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_q.weight.data = mmap[f\"model/tf_layers/{i}/1/to_q/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_k.weight.data = mmap[f\"model/tf_layers/{i}/1/to_k/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_v.weight.data = mmap[f\"model/tf_layers/{i}/1/to_v/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.weight.data = mmap[f\"model/tf_layers/{i}/1/to_out/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.bias.data = mmap[f\"model/tf_layers/{i}/1/to_out/bias/\"]\n",
    "\n",
    "    # gate_residual\n",
    "    if gate_residual:\n",
    "        '''\n",
    "        pt gru weights format is r,z,h\n",
    "        tf gru weights format is z,r,h\n",
    "        '''\n",
    "        getattr(getattr(pt_model.layers,i),\"2\").gru.weight_ih.data = reorder(mmap[f\"model/tf_layers/{i}/2/gru/kernel/\"])\n",
    "        getattr(getattr(pt_model.layers,i),\"2\").gru.weight_hh.data = reorder(mmap[f\"model/tf_layers/{i}/2/gru/recurrent_kernel/\"])\n",
    "        ih,hh = mmap[f\"model/tf_layers/{i}/2/gru/bias/\"].unbind(0)\n",
    "        getattr(getattr(pt_model.layers,i),\"2\").gru.bias_ih.data = reorder(ih)\n",
    "        getattr(getattr(pt_model.layers,i),\"2\").gru.bias_hh.data = reorder(hh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pt_outputs = pt_model(pt_x)\n",
    "tf_outputs = tf_model(tf_x)\n",
    "tf_outputs = torch.from_numpy(tf_outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean difference tensor(5.0120e-07)\n"
     ]
    }
   ],
   "source": [
    "print(\"mean difference\",(pt_outputs-tf_outputs).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "max difference tensor(1.3351e-05)\n"
     ]
    }
   ],
   "source": [
    "print(\"max difference\",(pt_outputs-tf_outputs).abs().max())"
   ]
  }
 ]
}