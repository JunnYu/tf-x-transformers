{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit1d867bd8aa154576b0fa62babcf552d0",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "086317466957d500e1e3add5d1080e4cde135e955220d9fc98fd7fe59df8a909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from x_transformers import XTransformer as PTXTransformer\n",
    "from tf_x_transformers import XTransformer as TFXTransformer\n",
    "from tf_fast_api import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_depth = 6\n",
    "dec_depth = 6\n",
    "tie_token_emb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = PTXTransformer(\n",
    "    dim = 512,\n",
    "    enc_num_tokens = 256,\n",
    "    enc_depth = enc_depth,\n",
    "    enc_heads = 8,\n",
    "    enc_max_seq_len = 1024,\n",
    "    dec_num_tokens = 256,\n",
    "    dec_depth = dec_depth,\n",
    "    dec_heads = 8,\n",
    "    dec_max_seq_len = 1024,\n",
    "    tie_token_emb = tie_token_emb      # tie embeddings of encoder and decoder\n",
    ")\n",
    "model.eval()\n",
    "src = torch.randint(0, 256, (1, 1024))\n",
    "src_mask = torch.ones_like(src).bool()\n",
    "tgt = torch.randint(0, 256, (1, 1024))\n",
    "tgt_mask = torch.ones_like(tgt).bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\yujun\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.070344924926758"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "class TMP(keras.Model):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = TFXTransformer(\n",
    "            dim = 512,\n",
    "            enc_num_tokens = 256,\n",
    "            enc_depth = enc_depth,\n",
    "            enc_heads = 8,\n",
    "            enc_max_seq_len = 1024,\n",
    "            dec_num_tokens = 256,\n",
    "            dec_depth = dec_depth,\n",
    "            dec_heads = 8,\n",
    "            dec_max_seq_len = 1024,\n",
    "            tie_token_emb = tie_token_emb      # tie embeddings of encoder and decoder\n",
    "        )\n",
    "    def call(self,a,b,c,d):\n",
    "        return self.model(a, b, src_mask = c, tgt_mask = d)\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "tfmodel = TMP()\n",
    "tf_src = tf.constant(src.numpy())\n",
    "tf_src_mask = tf.constant(src_mask.numpy())\n",
    "tf_tgt = tf.constant(tgt.numpy())\n",
    "tf_tgt_mask = tf.constant(tgt_mask.numpy())\n",
    "tf_loss = tfmodel(tf_src, tf_tgt,tf_src_mask,tf_tgt_mask) # (1, 1024, 512)\n",
    "tf_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skipping non-model layer _CHECKPOINTABLE_OBJECT_GRAPH\n"
     ]
    }
   ],
   "source": [
    "tf_path = \"./ckpts/checkpoint\"\n",
    "tfmodel.save_weights(tf_path)  \n",
    "init_vars = tf.train.list_variables(tf_path)\n",
    "names = []\n",
    "arrays = []\n",
    "layer_depth = []\n",
    "for full_name, shape in init_vars:\n",
    "    if full_name == \"_CHECKPOINTABLE_OBJECT_GRAPH\" or full_name[0] in [\"global_step\", \"save_counter\"]:\n",
    "        print(f\"Skipping non-model layer {full_name}\")\n",
    "        continue\n",
    "    names.append(full_name.replace(\".ATTRIBUTES/VARIABLE_VALUE\",\"\").replace(\"model/\",\"\"))\n",
    "    array = tf.train.load_variable(tf_path, full_name)\n",
    "    array = torch.from_numpy(array)\n",
    "    if \"kernel\" in names[-1]:\n",
    "        array = array.T\n",
    "    arrays.append(array)\n",
    "mmap = dict(zip(names,arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = model.encoder.attn_layers\n",
    "prefix = \"encoder/attn_layers\"\n",
    "for i,layer in enumerate(pt_model.layer_types): \n",
    "    is_last = i==len(pt_model.layer_types)-1\n",
    "    i = str(i)\n",
    "    if layer == \"f\" :\n",
    "        if not is_last:\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/0/gamma/\"]\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "        getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-0/kernel/\"]\n",
    "        getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-0/bias/\"]\n",
    "        getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-1/kernel/\"]\n",
    "        getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-1/bias/\"]\n",
    "\n",
    "    elif layer ==\"a\" or layer==\"c\":\n",
    "        getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/0/gamma/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_q.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_q/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_k.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_k/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_v.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_v/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_out/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_out/bias/\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = model.decoder.net.attn_layers\n",
    "prefix = \"decoder/net/attn_layers\"\n",
    "for i,layer in enumerate(pt_model.layer_types): \n",
    "    is_last = i==len(pt_model.layer_types)-1\n",
    "    i = str(i)\n",
    "    if layer == \"f\" :\n",
    "        if not is_last:\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/0/gamma/\"]\n",
    "            getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "        getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-0/kernel/\"]\n",
    "        getattr(getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"0\"),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-0/bias/\"]\n",
    "        getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-1/kernel/\"]\n",
    "        getattr(getattr(getattr(pt_model.layers,i),\"1\").net,\"2\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/net/layer_with_weights-1/bias/\"]\n",
    "\n",
    "    elif layer ==\"a\" or layer==\"c\":\n",
    "        getattr(getattr(pt_model.layers,i),\"0\").weight.data = mmap[f\"{prefix}/tf_layers/{i}/0/gamma/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"0\").bias.data = mmap[f\"{prefix}/tf_layers/{i}/0/beta/\"]\n",
    "\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_q.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_q/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_k.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_k/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_v.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_v/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.weight.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_out/kernel/\"]\n",
    "        getattr(getattr(pt_model.layers,i),\"1\").to_out.bias.data = mmap[f\"{prefix}/tf_layers/{i}/1/to_out/bias/\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.token_emb.weight.data  = mmap['encoder/token_emb/embeddings/']\n",
    "model.encoder.pos_emb.emb.weight.data = mmap['encoder/pos_emb/emb/embeddings/']\n",
    "try:\n",
    "    model.decoder.net.token_emb.weight.data = mmap['decoder/net/token_emb/embeddings/']\n",
    "    model.decoder.net.pos_emb.emb.weight.data= mmap['decoder/net/pos_emb/emb/embeddings/']\n",
    "except:\n",
    "    pass\n",
    "model.encoder.norm.weight.data = mmap['encoder/norm/gamma/']\n",
    "model.encoder.norm.bias.data = mmap['encoder/norm/beta/']\n",
    "\n",
    "model.decoder.net.norm.weight.data  = mmap['decoder/net/norm/gamma/']\n",
    "model.decoder.net.norm.bias.data  = mmap['decoder/net/norm/beta/']\n",
    "model.decoder.net.to_logits.weight.data  = mmap['decoder/net/to_logits/kernel/']\n",
    "model.decoder.net.to_logits.bias.data  = mmap['decoder/net/to_logits/bias/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss1 = model(src, tgt, src_mask = src_mask, tgt_mask = tgt_mask) # (1, 1024, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4.7684e-07)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "(loss1 - torch.tensor(tf_loss.numpy())).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4.7684e-07)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "(loss1 - torch.tensor(tf_loss.numpy())).abs().max()"
   ]
  }
 ]
}